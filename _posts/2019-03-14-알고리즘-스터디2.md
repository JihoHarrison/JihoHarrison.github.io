---
layout: post
title:  "알고리즘 스터디 @효율적인 알고리즘@"
date:   2019-03-28 18:34:10 +0700
categories: [algorithm]
---


> <알기 쉬운 알고리즘, 양성봉, 생능출판> 책으로 공부한 알고리즘

<br>


## ⌚️ 가장 오래된 알고리즘
--- 

-  가장 오래된 알고리즘은 기원전 300년경에 만들어졌는데 __유클리드의 최대 공약수를 찾는 알고리즘__ 이다

	유클리드가 생각해낸 두 수의 최대공약수를 구하는 방법은

	> 두 수의 최대공약수 = (두 수 중 큰수 - 작은수) 와 두 수 중 작은 수와의 최대공약수

	이다. 직접 해보면 진짜로 같다!

	이 방법으로 한번 24와 14의 최대공약수를 구해보면,

	> __24와 14의 최대 공약수__ = (24 - 14)와 14의 최대공약수 = 10과 14의 최대공약수 
	> 
	> = (14 - 10)와 10의 최대공약수 = __4와 10의 최대공약수__
	>
	> = (10 - 4)와 4의 최대공약수 = __6과 4의 최대공약수__
	>
	> = (6 - 4)와 4의 최대공약수 = __2와 4의 최대공약수__
	>
	> = (4 - 2)와 2의 최대공약수 = __2와 2의 최대공약수__
	>
	> = (2 - 2)와 2의 최대공약수 = __0과 2의 최대공약수__ = __2__ (0과 어떤 수의 최대공약수는 어떤 수 이다)					   

	위 뺄셈 과정은 나머지 연산으로 똑같이 표현할 수 있는데 나머지 연산으로 계산하면 뺄셈으로 계산하는 것보다 훨씬 빠르게 해를 찾을 수 있다. 

	왜냐하면 뺄셈 과정 중 몇 개가 생략되기 때문이다.

	위 뺄셈 과정은 아래와 같은 나머지 연산으로 대체될 수 있다.

	> __24와 14의 최대 공약수__ = 두 수 중 작은 수와 (큰 수에서 작은 수를 나눈 나머지)

	이 방법으로 다시 구해보면,

	> __24와 14의 최대 공약수__ = __14와 10의 최대공약수__
	>
	> = __10과 4의 최대 공약수__
	>
	> = __4와 2의 최대 공약수__
	>
	> = __2와 0의 최대 공약수__ = __2__ 

	이렇게 더 단축된 과정으로 최대 공약수가 구해진다

	위 과정을 자세히 살펴보면 두 수중 작은수를 선택하고, 큰수에서 작은 수를 나눈 수를 선택하는 과정을 반복하는 모습을 볼 수 있다. 이렇게 같은 과정을 반복하는 코드를 짜야 한다면 _재귀함수_ 를 활용하는 것이 좋다.

	_재귀함수_

	하나의 함수 안에서 자신을 다시 호출하여 작업을 수행하는 방식으로 문제를 푸는 방식에서 사용되는 함수.

	~~~c
		int gcd(int m, int n){
			if(n == 0){
				return m;
			}else{
				return gcd(n, m%n);
			}
		}	
		//매개변수를 넣을 때 조건은 m > n 이다
		//gcd어원 = greatest common divisor = 최대 공약수
	~~~

	위는 재귀함수를 이용하여 최대공약수를 구하는 코드이다 

	__재귀함수를 호출할 때는 return 뒤에 호출한다__ 


	<br>

## 🕣🕘 알고리즘은 효율성을 따져야 한다!
--- 


- 왜 효율적인 알고리즘을 구현하려고 노력할까?

	동일한 문제를 해결해주는 여러 개의 알고리즘이 있을 때 당연히 시간상 빨리 문제를 해결해주는 알고리즘이 더 효율적이고 좋은 알고리즘이라고 생각이 든다.

	실제로 2개의 서로 다른 정렬 알고리즘을 사용해서 10억개의 숫자를 실제 PC에서 정렬해보자고 하자. 둘 중 빠른 정렬 알고리즘은 10억개의 숫자를 정렬하는데 5분이 걸리는 반면, 느린 정렬 알고리즘은 10억개를 정렬하는데 300년이 걸린다. ㄷㄷ..

	입력 크기가 작으면 빠른 알고리즘을 사용하든 느린 알고리즘을 사용하든 비슷한 수행 시간이 걸리지만 입력 크기가 커지면 커질수록 수행시간의 차이는 점점 커지게 된다.

	따라서 우리는 효율적인 알고리즘을 구현하여 좀 더 빠른 시간에 답을 구하기 위해 노력해야하는 것이다.  

	<br>

- 	알고리즘이 얼마나 효율적인지 볼 수 있는 표현식이 있다!

	알고리즘의 효율성은 두 가지 면으로 따져볼 수 있는데 __수행 시간__ 과 __사용되는 메모리 공간의 크기__ 로 따질 수 있다. 

	이 두 가지는 살짝쿵 전문 용어로 __시간복잡도__ 와 __공간복잡도__ 라고 표현한다

	우선 어떤 알고리즘의 수행시간이 얼마나 걸리는지를 어떻게 알아내는지 생각해보자 ( 즉, 어떤 알고리즘의 시간 복잡도가 얼마인지를 생각해보자는 것과 같다 )

	가장 쉬운 방법은 해당 알고리즘을 컴퓨터에서 실행시켜 수행된 시간을 측정해 보는 것이다. 
	
	이 방법은 단점이 있는데 실행시켜본 컴퓨터의 사양에 따라 수행된 시간이 달라질 수 있다는 점이다




	<br>


## 📝 어떤 알고리즘의 시간복잡도 표현하기
--- 


- 위에서 설명한 바와 같이 수행 시간은 환경에 영향을 많이 받는다. 그래서 좀 더 객관적인 시간복잡도를 알아보기 위해 우리는 __해당 알고리즘이 수행하는 기본적인 연산횟수를 입력 크기에 대한 함수__ 를 시간복잡도라고 생각한다

	입력 크기에 대한 함수라는 말은 입력 크기를 문자 n으로 표시한다고 하면 이 함수는 n에 대한 함수로 나타내진다는 말이다.

	> 정리 ) 시간복잡도 = 해당 알고리즘이 수행하는 기본연산의 횟수를 입력 크기에 대한 함수로 나타낸 것.

	예를 들어, 10개의 숫자 중 가장 큰 숫자를 찾는 알고리즘이 있다고 하자. 이 알고리즘의 기본적인 연산은 숫자를 비교하는 비교 연산이고, 비교를 총 9번 한다. 또, 이 알고리즘의 입력 크기는 10이다.

	__이것을 n을 사용하여 일반화 시켜보면 n장의 카드가 있을 때 n-1번의 비교를 수행하므로 이 알고리즘의 시간복잡도는 n-1 이다!!__

- 	위와 같은 어떤 알고리즘의 시간복잡도를 표현하기 위해 알고리즘을 분석하는 방법으로는 

	- 최악 경우 분석
	- 평균 경우 분석
	- 최선 경우 분석

	이 3가지 분석 방법으로 알고리즘을 시간적 측면에서 분석하여 시간복잡도를 구한다.

	주로 최악 경우 분석방법을 사용하는데 __이 알고리즘은 어떤 입력이 주어지더라도 수행 시간이 얼마 이상을 넘지 않는다__ 라는 의미를 가지고 있다

	즉, 최고로 늦어도 얼마만큼의 시간안에는 끝난다 라는 뜻이다.

	<br>

## 📈 시간 복잡도 (또는 공간 복잡도) 의 점근적 표기
--- 

-  시간 복잡도는 입력 크기 n에 대한 함수로 나타내지는데 주로 f(n) 으로 표현되는 다항식이 나온다. 이 다항식을 좀 더 단순한 함수로 표현하기 위해 우리는 점근적 표기를 사용한다

	점근적 표기는 입력 크기 n이 무한대로 커질 때의 시간복잡도 함수를 간단히 표현할 수 있게 해준다

- 시간 복잡도를 점근적 표기를 사용하여 나타내는 방법

	- 1단계 ) 원래의 복잡한 시간 복잡도의 다항식에서 최고차항만을 계수 없이 취한다. f(n)을 단순화하는 과정이다.
	- 2단계 ) 1단계에서 얻은 식에 상한, 하한, 동일한 증가율과 같은 개념을 적용한다

	1단계에서 얻은 식에 상한 개념을 적용시킨 것을 __O표기(빅오) = 점근적 상한__ 라고 하고, 하한 개념을 적용시킨 것을 __Ω표기(빅오메가) = 점근적 하한__ 이라고 하며, 상한과 하한을 동사에 적용시킨 것을 __θ표기(세타)__ 라고 한다 

- _빅오(O) 표기법_

	어떤 알고리즘의 복잡도가 f(n) = 2n^2 - 8n + 3 이라고 하자. (대부분 복잡도는 시간 복잡도를 나타내고 n에 대한 다항식으로 나온다 )

	1단계에 따라 f(n)을 단순화 하여 얻은 식은 n^2이다

	2단계로 n^2에 상한 개념을 적용시켜 보자. 

	> __상한 개념을 n이 증가함에 따라 부여하는 과정__
	>
	> 단순화된 함수 n^2에 임의의 상수 c를 곱한 cn^2이 n이 증가함에 따라 f(n)의 상한이 된다 (단, c>0)

	![복잡도1](https://user-images.githubusercontent.com/31889335/55290829-25fd9b80-5413-11e9-80b3-cc017fd5bab2.PNG)

	단순화된 함수에 c를 곱한 함수는 원래 함수인 f(n)과 비교하면 어떠한 시점 n0 에서 이후가 위와 같은 그래프로 나타내지는 경우 f(n)의 상한이라고 한다 (단, n0의 값은 양수이다)

	위 그림을 만족시키는 c와 n0가 존재한다면 우리는 앞으로 __f(n) = O(n^2)__ 라고 표현한다

	O( )안의 함수는 n^2 만 될 수 있는 것이 아니다. 예를 들어 n^3도 될 수 있는데 어떤 양의 상수 c에 대하여 cn^3 > 2n^2 - 8n + 3이 성립하기 때문이다

	일반적인 상한을 나타내는 그래프는 

	![복잡도2](https://user-images.githubusercontent.com/31889335/55290933-64478a80-5414-11e9-90a9-17ef6c3dac23.PNG)


	위 그래프이다. n이 증가함에 따라 O(g(n))이 점근적 상한이라는 것을 보여준다.f()

	즉, cg(n)이 n0보다 큰 모든 n에 대해서 항상 f(n)보다 크다!

- _오메가(Ω) 표기법_

	f(n) = 2n^2 -8n + 3 의 복잡도를 가지는 알고리즘이 있다고 했을 때, __n이 증가함에 따라 2n^2 -8n + 3이 cn^2보다 작을 수 없다__ 라는 의미를 가지는 c를 찾으면 된다

	![복잡도3](https://user-images.githubusercontent.com/31889335/55325444-15572f00-54c0-11e9-940a-35c29f1a9c5c.PNG)

	위 그림은 오메가표기법으로 나타낸 복잡도의 일반식 그래프이다.

	n이 증가함에 따라 Ω(g(n))이 점근적 하한이라는 것을 보여준다. 

	즉, cg(n) 이 n0보다 큰 모든 n에 대해서 항상 f(n) 보다 작다는 것이다.

- _세타(θ) 표기법_

	세타 표기는 O표기와 Ω표기가 같은 경우에만 사용한다. 

	즉, f(n) = O(n^2) 를 만족하고 f(n) = Ω(n^2) 일 경우 f(n) = θ(n^2) 이다.

	f(n)은 n이 증가함에 따라 n^2과 동일한 증가율을 가진다 라는 의미이다.

	![복잡도4](https://user-images.githubusercontent.com/31889335/55325705-c4940600-54c0-11e9-8b91-3c908f628aa8.PNG)

	위 그래프는 f(n) 과 세타 표기의 관계를 나타낸 그래프이다.

	즉, n0보다 큰 모든 n에 대해서 f(n) 이 c2g(n)인 상한과 c1g(n)인 하한을 모두 만족한다는 것이다.